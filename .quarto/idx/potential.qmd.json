{"title":"The interconnectedness between regions and technologies","markdown":{"headingText":"The interconnectedness between regions and technologies","containsRefs":false,"markdown":"\n## Methodological Motivation\n\nTraditional relatedness frameworks model diversification through symmetric co-occurrence matrices and linear aggregation of relatedness density [@hausmann2011network]. However, as established in our problem statement, these constructs suffer from three structural limitations: (1) symmetry assumptions that obscure directional dependencies between technologies, (2) linear aggregation that loses granular information about technology-specific requirements, and (3) noise when technologies outnumber regions. \n\nWe address these limitations by replacing traditional measures with machine learning-derived alternatives. Specifically, we use Random Forest models to generate: (1) **asymmetric feature importance networks (FITS)** that capture directional, hierarchical technology relationships, replacing symmetric relatedness measures; and (2) **predicted probabilities (technological potential)** that estimate region-specific feasibility of technology adoption, replacing linear relatedness density. This approach enables the contextualization of diversification strategies by accounting for technology-specific characteristics, regional knowledge infrastructure, and broader spatial dynamics—elements that traditional measures cannot adequately capture.\n\nBefore detailing our methodology, we briefly situate this approach within the broader literature. The Principle of Relatedness (PoR) formalizes the empirical observation that shared input requirements (knowledge, resources, capabilities) determine diversification feasibility [@hidalgo2018principle; @hidalgo2021economic]. Economic Complexity (EC) complements this by quantifying sophistication patterns [@hidalgo2009building]. While these frameworks have proven valuable for policy [@zaccaria2018integrating; @albora2021economic], deriving granular, context-specific implications remains challenging [@hidalgo2023policy; @li2024evaluating]. Recent work on unrelated diversification [@pinheiro2022time; @boschma2023role], geographic inequalities [@pinheiro2025dark; @hartmann2017linking], and emerging technologies [@lee2018early; @fessina2024identifying] highlights the need for methodologies that capture contextual nuances beyond path dependency identification.\n\nOur approach responds to this need by modeling technology relationships and regional capabilities in ways that explicitly incorporate heterogeneity. The following sections establish our notation system, describe the Random Forest algorithm, and detail how we construct and interpret technological potential, FITS, and coherence measures.\n\n## Notation and Data Structure\n\nWe establish consistent notation used throughout:\n\n**Sets:**\n\n- $\\mathcal{T} = \\{t : 1 \\le t \\le N_T\\}$: set of technologies\n- $\\mathcal{R} = \\{r : 1 \\le r \\le N_R\\}$: set of regions  \n- $\\mathcal{Y} = \\{y : 1 \\le y \\le N_Y\\}$: set of years\n- $\\mathcal{C} = \\{c : 1 \\le c \\le N_C\\}$: set of technology categories\n- $\\mathcal{K} = \\{\\kappa : 1 \\le \\kappa \\le N_{\\kappa}\\}$: set of countries\n\n\n\nWe use European Patent Office data (1978-2021) classified at the 4-digit IPC level, yielding 641 distinct technologies across 345 NUTS2 regions in 34 European countries. IPC classifications provide hierarchical structure: section (letter, we also refer to this as categories), class (two digits), subclass (letter). For example, F16H encompasses Section F (Mechanical engineering), Class 16 (engineering elements for mechanical power transmission), and Subclass H (gearing systems). We supplement patent data with Eurostat regional socio-economic indicators detailed in subsequent sections.\n\n## Revealed Technological Advantage\n\nWe quantify regional specialization using the Revealed Comparative Advantage [@balassa1965rca]. Although originally designed for trade data, this metric has been widely adopted in innovation geography literature. Following @balland2017geography, we refer to it as Revealed Technological Advantage (RTA) in our patent context. The RTA measures relative specialization, enabling simultaneous capture of expertise depth and portfolio diversity while reducing co-occurrence noise [@fessina2024identifying]. Despite critiques regarding patent-based applications [@balland2019beyond; @diodato2023economic], RTA aligns with our objective of capturing meaningful technology relationships through machine learning rather than raw co-occurrence.\n\nThe RTA for region $r$ in technology $t$ during year $y$ is:\n\n$$\n\\text{RTA}_{r,t,y}\n= \\frac{\\displaystyle\\frac{X_{r,t,y}}{\\sum_{t'} X_{r,t',y}}}\n       {\\displaystyle\\frac{\\sum_{r'} X_{r',t,y}}{\\sum_{r',t'} X_{r',t',y}}}\n= \\frac{X_{r,t,y}\\,\\sum_{r',t'}X_{r',t',y}}\n       {\\bigl(\\sum_{t'}X_{r,t',y}\\bigr)\\,\\bigl(\\sum_{r'}X_{r',t,y}\\bigr)}\n$$\nWhere, $X_{r,t,y}$: patent count for region $r$ in technology $t$ during year $y$\n\nFor each year $y$, we construct the RTA matrix $\\mathbf{R}^{(y)}$ with entries $\\text{RTA}_{r,t,y}$:\n\n$$\n\\mathbf{R}^{(y)}\n= \\bigl[\\text{RTA}_{r,t,y}\\bigr]_{r=1,\\dots,N_{R}}^{t=1,\\dots,N_{T}}\n$$\n\nThese yearly matrices form the foundation for all subsequent modeling. We then binarize specialization for classification tasks:\n\n$$\nz_{r,t,y}\n\\;=\\;\n\\begin{cases}\n1 & \\text{if }\\text{RTA}_{r,t,y}\\ge1 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\n\nwhere $z_{r,t,y} = 1$ indicates region $r$ has comparative advantage (specialization) in technology $t$ at year $y$.\n\n## Random Forest Algorithm\n\nBefore detailing our applications, we provide comprehensive context on the Random Forest algorithm, which fuels our entire methodological approach. We focus on binary classification where $y_i \\in \\{0,1\\}$.\n\n### Algorithm Structure\n\nRandom Forest constructs an ensemble of $B$ decision trees through bootstrap aggregating (bagging) with random feature subsampling. Each tree $T_b$ is built on a bootstrap sample $\\mathcal{D}_b^*$ drawn with replacement from the original dataset.\n\n### Tree Construction via Recursive Partitioning\n\nEach tree recursively partitions the feature space through binary splits. At node $t$, we randomly select $m$ features (typically $m = \\sqrt{p}$) and evaluate all possible splits within this subset. For feature $j$ and threshold $\\tau$, the split creates two child nodes: $t_L = \\{i : x_{ij} \\leq \\tau\\}$ and $t_R = \\{i : x_{ij} > \\tau\\}$.\n\n### Gini Impurity as Split Criterion\n\nSplit quality is assessed via Gini impurity:\n\n$$G(t) = 1 - \\sum_{k=0}^{1} p_k^2(t) = 2p_0(t)p_1(t)$$\n\nwhere $p_k(t) = n_k(t)/n(t)$ represents the proportion of class $k$ observations at node $t$. Gini impurity quantifies node heterogeneity: $G=0$ indicates perfect purity (homogeneous class), while $G=0.5$ indicates maximum impurity (equal class distribution). The optimal split maximizes weighted impurity reduction:\n\n$$\\Delta G(j, \\tau) = G(t) - \\left[\\frac{n(t_L)}{n(t)} G(t_L) + \\frac{n(t_R)}{n(t)} G(t_R)\\right]$$\n\nWeighting by relative node size prevents trivial splits that isolate single observations into pure but uninformative leaves.\n\n### Termination and Class Assignment\n\nRecursive splitting continues until predefined stopping criteria: node purity ($G=0$), minimum node size threshold, or maximum tree depth. Terminal nodes are assigned the majority class of their constituent observations.\n\n### Ensemble Prediction\n\nFor prediction, observation $\\mathbf{x}$ traverses all $B$ trees. Final classification aggregates individual tree predictions via majority voting:\n\n$$\\hat{y}(\\mathbf{x}) = \\text{mode}\\{\\hat{y}_1(\\mathbf{x}), \\ldots, \\hat{y}_B(\\mathbf{x})\\}$$\n\nClass probabilities are estimated as the proportion of trees predicting each class:\n\n$$\\hat{P}(y=1|\\mathbf{x}) = B^{-1}\\sum_{b=1}^{B} \\mathbb{I}[\\hat{y}_b(\\mathbf{x})=1]$$\n\nThis probability represents empirical vote share across trees. Values near 1 indicate strong consensus for class 1 (high confidence), while values near 0.5 reflect uncertainty. Unlike parametric models, these are data-driven vote proportions rather than model-based probability estimates.\n\n### Variance Reduction Mechanism\n\nThe algorithm's effectiveness stems from variance reduction through decorrelated predictions. Bootstrap sampling and random feature selection reduce inter-tree correlation $\\rho$, yielding ensemble variance:\n\n$$\\text{Var}(\\bar{y}) = \\rho\\sigma^2 + \\frac{1-\\rho}{B}\\sigma^2$$\n\nAs $B$ increases and $\\rho$ decreases, ensemble variance diminishes while maintaining the low bias of flexible tree models.\n\n### Feature Importance\n\nFeature importance quantifies each predictor's contribution by aggregating Gini impurity reductions:\n\n$$I(j) = \\frac{1}{B}\\sum_{b=1}^{B} \\sum_{t \\in T_b : v(t)=j} \\Delta G(t)$$\n\nwhere the sum runs over all nodes using feature $j$ for splitting. Higher values indicate features consistently creating purer partitions. Feature importance measures predictive association rather than causal effect, and suffers from bias toward high-cardinality features and correlated predictor sets. It ranks predictive relevance but requires caution in causal interpretation.\n\n## Connecting Random Forest to the Relatedness Framework\n\nWe apply Random Forest in two complementary ways that replace traditional relatedness constructs:\n\n**A. Technological Potential** estimates $p_{r,t,y}$ = probability of future specialization in technology $t$ for region $r$. This replaces **relatedness density**—instead of linearly aggregating symmetric co-occurrence frequencies, we predict region-specific feasibility using past technology portfolios. This captures non-linear interactions and regional heterogeneity that linear measures miss.\n\n**B. Feature Importance Technology Space (FITS)** extracts $I_{t \\to t'}$ = directional dependencies between technologies. This replaces **symmetric relatedness**—instead of co-occurrence frequencies, we identify which technologies predict others' future adoption. Asymmetry reveals hierarchical structures: if $I_{t \\to t'} \\gg I_{t' \\to t}$, technology $t$ is a prerequisite or \"stepping stone\" toward $t'$.\n\nTogether, these measures enable contextualized diversification analysis: FITS reveals technology-level hierarchies, Potential quantifies region-specific feasibility, and their combination allows testing how regional infrastructure, national ecosystems, and spatial factors moderate technology adoption patterns.\n\n\n```{mermaid}\n\ngraph TB\n    A[Input: RCA values<br/>for all technologies<br/>except target] --> B[Tree 1]\n    A --> C[Tree 2]\n    A --> D[Tree 3]\n    A --> E[...]\n    A --> F[Tree B]\n    \n    B --> G[Vote: 1]\n    C --> H[Vote: 0]\n    D --> I[Vote: 1]\n    E --> J[Vote: 1]\n    F --> K[Vote: 1]\n    \n    G --> L[Aggregate Votes]\n    H --> L\n    I --> L\n    J --> L\n    K --> L\n    \n    L --> M[Probability = 4/5 = 0.80<br/>Region will specialize<br/>in target technology]\n    \n    style A fill:#e1f5ff\n    style M fill:#ffe1e1\n\n```\n\n\n## Technological Potential\n\nWe follow the methodology of @albora2023product, originally developed for trade data. The innovation lies in modeling each technology separately rather than constructing a single global model. For every technology $i \\in \\mathcal{T}$, we train a binary classification model where:\n\n- **Outcome**: $z_{r,i,y}$ (whether region $r$ specializes in technology $i$ at year $y$)\n- **Features**: $\\{\\text{RTA}_{r,t,y-\\delta} : t \\in \\mathcal{T}, t \\neq i\\}$ (RTA values for all other technologies $\\delta$ years prior)\n\nThis technology-specific approach enables each model to learn unique dependency patterns. Setting $\\delta = 4$ years balances predictive performance with data availability such that current capacity predict future ones [@andreoni2019political]. \n\n### Training Procedure\n\nWe predict specialization for target years $y_t \\in \\{2008, \\ldots, 2018\\}$ using data from 1978 onward. For each target year $y_t$ and technology $i$:\n\n**Training set:**\n$$\nX_{\\text{train}} = \\{ \\text{RTA}_{r,t,y} \\mid y \\in [1978, y_t - 2\\delta], t \\neq i\\}\n$$\n$$\nY_{\\text{train}} = \\{z_{r,i,y} \\mid y \\in [1978 + \\delta,  y_t - \\delta]\\}\n$$\n\n**Test set:**\n$$\nX_{\\text{test}} = \\{ \\text{RTA}_{r,t,y_t-\\delta} \\mid t \\neq i\\}\n$$\n$$\nY_{\\text{test}} = \\{z_{r,i,y_t}\\}\n$$\n\nThis produces 7,051 models (641 technologies × 11 years). Given computational constraints, we performed cross-validation on a random sample of four technologies (G06G, B67B, D02J, C08J) and applied the most frequent optimal parameters across all models: `mtry = 139`, `trees = 100`, `min_n = 38`. Training was conducted in R using the Ranger package [@wright2017ranger], orchestrated via the targets pipeline [@landau2021targets] within the tidymodels framework.\n\n### Output: Regional Technological Potential\n\nEach model produces probabilities $p_{r,i,y} = P(z_{r,i,y} = 1 \\mid \\text{RTA}_{r,\\cdot,y-\\delta})$ representing the likelihood that region $r$ develops specialization in technology $i$ at year $y$ given its past portfolio. These probabilities constitute **regional technological potential**—a forward-looking, region-specific measure of diversification feasibility.\n\nAggregating across technologies yields average regional potential:\n\n$$p_{r,y} = \\frac{\\sum_{t} p_{r,t,y}}{N_T}$$\n\n### Conceptual Interpretation\n\nTechnological potential differs fundamentally from relatedness density. While relatedness density assumes technologies combine linearly and symmetrically, potential:\n\n1. Captures **non-linear interactions** between technologies through Random Forest's decision tree structure\n2. Allows **asymmetric dependencies** where technology $t$ may enable $t'$ but not vice versa\n3. Produces **region-specific estimates** rather than universal technology-pair relationships\n4. Reflects **time-varying dynamics** by training on expanding windows of historical data\n\n### Empirical Implications\n\nHigh potential ($p_{r,t,y} \\approx 1$) indicates a region's existing portfolio strongly predicts future specialization in technology $t$—the region likely possesses necessary complementary capabilities. Low potential ($p_{r,t,y} \\approx 0$) suggests capability gaps despite potential relatedness. Crucially, potential varies across regions for the same technology, enabling analysis of how regional knowledge infrastructure, national ecosystems, and spatial factors moderate diversification feasibility—our core research questions.\n\n## Feature Importance Technology Space (FITS)\n\nTraditional technology networks use patent citations or co-occurrence patterns. Citations suffer from three limitations: (1) examiner-added citations may not reflect actual knowledge flows, (2) aggregating patent-level citations to technology-level relationships obscures directionality, and (3) citation networks are backward-looking rather than predictive [@fessina2024identifying]. Co-occurrence networks face the issues outlined in our problem statement: symmetry, noise, and linear assumptions.\n\nFITS addresses these limitations by constructing asymmetric, predictive networks from machine learning. Rather than inferring relationships from co-occurrence, FITS extracts directional dependencies from the feature importance scores of our Technological Potential models.\n\n### FITS Construction\n\nRecall that for each technology $i$, we trained a Random Forest model predicting $z_{r,i,y}$ using $\\{\\text{RTA}_{r,t,y-\\delta} : t \\neq i\\}$ as features. The feature importance $I_i(t)$ quantifies how much technology $t$ contributes to predicting future specialization in technology $i$ across all regions and time periods in the training data.\n\nWe formalize FITS as a directed, weighted network $G = (V, E, W)$ where:\n\n- **Nodes** $V = \\mathcal{T}$: the set of technologies\n- **Edges** $E$: directed connections $(t \\to i)$ for all $t, i \\in \\mathcal{T}, t \\neq i$\n- **Weights** $W_{t \\to i} = I_i(t)$: feature importance of technology $t$ in model predicting technology $i$\n\nWe normalize weights within each target technology's model:\n\n$$\nW_{t \\to i} = \\frac{I_i(t)}{\\sum_{t' \\neq i} I_i(t')}\n$$\n\nensuring that for each technology $i$, incoming edge weights sum to 1: $\\sum_{t \\neq i} W_{t \\to i} = 1$.\n\n### Mathematical Formulation\n\nFrom the Random Forest algorithm, feature importance for technology $t$ in model $M_i$ (predicting technology $i$) is:\n\n$$\nI_i(t) = \\frac{1}{B}\\sum_{b=1}^{B} \\sum_{n \\in T_b : v(n)=t} \\Delta G(n)\n$$\n\nwhere the sum runs over all nodes $n$ in all trees $T_b$ that split on feature $t$, and $\\Delta G(n)$ is the Gini impurity reduction at node $n$. Technologies that consistently create purer partitions when predicting $i$ receive higher importance scores.\n\nThe full FITS network aggregates these relationships across all 641 technologies, producing a $641 \\times 641$ weighted adjacency matrix (excluding self-loops).\n\n### Asymmetry and Hierarchy\n\nCrucially, FITS is **asymmetric**: $W_{t \\to i} \\neq W_{i \\to t}$ in general. This asymmetry captures hierarchical technological dependencies:\n\n- If $W_{t \\to i} \\gg W_{i \\to t}$, technology $t$ is a **prerequisite** or **stepping stone** toward $i$ (expertise in $t$ predicts future $i$, but not vice versa)\n- If $W_{t \\to i} \\approx W_{i \\to t}$, technologies are **complementary peers** (mutual predictive relationships)\n- If $W_{t \\to i} \\ll W_{i \\to t}$, technology $i$ is a prerequisite toward $t$\n\nThis hierarchical structure is invisible to symmetric co-occurrence measures and reveals technological trajectories: regions can identify which current capabilities enable paths toward desired future technologies.\n\n### Conceptual Interpretation\n\nFITS edges represent **predictive dependencies** based on historical diversification patterns across all European regions. A strong edge $t \\to i$ indicates that regions with RTA in technology $t$ at time $y-\\delta$ frequently developed RTA in technology $i$ by time $y$, even after controlling for all other technologies. This is fundamentally different from co-occurrence (which measures simultaneous presence) or citations (which measure backward-looking knowledge flows).\n\n### Empirical Implications\n\nFITS enables novel analyses of technological landscapes:\n\n1. **Path identification**: For a target technology $i$, examine incoming edge weights to identify strong predictors (prerequisites)\n2. **Branching points**: High out-degree nodes represent foundational technologies enabling diverse future specializations\n3. **Category structure**: Aggregating edges by IPC categories reveals cross-domain dependencies (e.g., mechanical engineering → electronics)\n4. **Regional positioning**: Comparing a region's current portfolio against FITS edge patterns reveals strategic opportunities and gaps\n\nIn our empirical analysis, FITS allows testing whether technology-specific characteristics (position in the network hierarchy, in/out-degree patterns, category embeddings) moderate diversification outcomes—aspects traditional relatedness measures cannot capture.\n\n### Network Visualization\n\n![Technology Network (based on 2018 patent data)](resources/technology_network.png)\n\nThe figure displays the FITS network with nodes colored by IPC category, sized by total degree, and transparency reflecting eigenvector centrality. Labels appear for high-centrality technologies. The structure reveals dense within-category connections and sparse but critical between-category bridges.\n\n## Coherence: Bridging Technology Networks and Regional Portfolios\n\nFITS identifies technology-to-technology relationships. Technological Potential quantifies regional diversification feasibility. **Coherence** bridges these levels by measuring the alignment between a technology's position in the FITS network and a region's existing specialization structure.\n\n### Conceptual Motivation\n\nConsider two regions, both lacking specialization in technology $i$, both having similar potential $p_{r,i,y}$. However, Region A specializes in technologies that are strong predictors of $i$ (high incoming FITS edges), while Region B specializes in technologies unrelated to $i$ in the network. Coherence captures this difference: Region A has high coherence with $i$ (its portfolio aligns with $i$'s network prerequisites), while Region B has low coherence (misalignment).\n\nThis metric operationalizes the \"knowledge coherence\" and \"cognitive proximity\" concepts from innovation literature [@neffke2011how; @boschma2015towards] using our directional network structure. It enables testing whether diversification success depends not just on potential (predicted feasibility) but on the structural fit between regional portfolios and technology network positions.\n\n### Mathematical Construction\n\nFor each region $r$, technology $i$, and IPC category $c$, we construct two embedding vectors capturing $i$'s directional network position and compare them to $r$'s average embeddings for technologies in category $c$.\n\n**Technology embeddings** (individual technology $i$):\n\n- Incoming: $\\text{embcat\\_to}_{i,c} = \\frac{\\sum_{t \\in c} W_{t \\to i}}{|\\{t \\in c : W_{t \\to i} > 0\\}|}$ (average FITS weight from category $c$ to technology $i$)\n- Outgoing: $\\text{embcat\\_from}_{i,c} = \\frac{\\sum_{t' \\in c} W_{i \\to t'}}{|\\{t' \\in c : W_{i \\to t'} > 0\\}|}$ (average FITS weight from technology $i$ to category $c$)\n\n**Regional average embeddings** (region $r$, category $c$):\n\n- Incoming: $\\overline{\\text{embcat\\_to}}_{r,c} = \\frac{1}{|S_{r,c}|}\\sum_{t \\in S_{r,c}} \\text{embcat\\_to}_{t,c}$ where $S_{r,c} = \\{t \\in c : \\text{RTA}_{r,t,y} \\geq 1\\}$\n- Outgoing: $\\overline{\\text{embcat\\_from}}_{r,c} = \\frac{1}{|S_{r,c}|}\\sum_{t \\in S_{r,c}} \\text{embcat\\_from}_{t,c}$\n\n**Coherence** is the cosine similarity between technology $i$'s directional embeddings and region $r$'s average directional embeddings for category $c$:\n\n$$\n\\text{Coherence}_{r,i,c,y} = \\frac{\\mathbf{v}_1 \\cdot \\mathbf{v}_2}{||\\mathbf{v}_1|| \\cdot ||\\mathbf{v}_2||}\n$$\n\nwhere:\n\n- $\\mathbf{v}_1 = [\\text{embcat\\_to}_{i,c}, \\overline{\\text{embcat\\_to}}_{r,c}]$\n- $\\mathbf{v}_2 = [\\text{embcat\\_from}_{i,c}, \\overline{\\text{embcat\\_from}}_{r,c}]$\n\n\n\n```{mermaid}\n%%{init: {'theme':'base', 'themeVariables': {'fontSize':'12px'}}}%%\ngraph TB\n    subgraph \"Technology Network\"\n        A[Tech A<br/>Cat: A]\n        B[Tech B<br/>Cat: B]\n        C[Tech C<br/>Cat: C]\n        D[Tech D<br/>Cat: D]\n        \n        A -->|w=0.8| B\n        A -->|w=0.5| C\n        B -->|w=0.6| A\n        C -->|w=0.9| A\n        D -->|w=0.4| A\n    end\n    \n    subgraph \"Step 1: Technology i Embeddings\"\n        direction TB\n        to[Incoming to Tech A:<br/>From Cat B: 0.6<br/>From Cat C: 0.9<br/>From Cat D: 0.4]\n        from[Outgoing from Tech A:<br/>To Cat B: 0.8<br/>To Cat C: 0.5]\n        \n        calc_to[embcat_to_A,B = 0.6/1 = 0.6<br/>embcat_to_A,C = 0.9/1 = 0.9<br/>embcat_to_A,D = 0.4/1 = 0.4]\n        calc_from[embcat_from_A,B = 0.8/1 = 0.8<br/>embcat_from_A,C = 0.5/1 = 0.5]\n        \n        to --> calc_to\n        from --> calc_from\n    end\n    \n    subgraph \"Step 2: Regional Benchmarks\"\n        direction TB\n        reg[Region r has RCA≥1 in:<br/>Tech A Cat A<br/>Tech E Cat B<br/>Tech F Cat C]\n        \n        reg_calc[Regional averages for specialized techs:<br/>mean embcat_to for Cat B = 0.7<br/>mean embcat_from for Cat B = 0.75<br/>mean embcat_to for Cat C = 0.85<br/>mean embcat_from for Cat C = 0.6]\n    end\n    \n    subgraph \"Step 3: Construct Vectors\"\n        direction TB\n        v1_construct[v₁ incoming pattern:<br/>v₁ = embcat_to_A,B, mean_to_r,B<br/>v₁ = 0.6, 0.7]\n        v2_construct[v₂ outgoing pattern:<br/>v₂ = embcat_from_A,B, mean_from_r,B<br/>v₂ = 0.8, 0.75]\n    end\n    \n    subgraph \"Step 4: Compute Cosine Similarity\"\n        direction TB\n        dot[Dot product:<br/>v₁·v₂ = 0.6×0.8 + 0.7×0.75<br/>= 0.48 + 0.525 = 1.005]\n        norm[Norms:<br/>||v₁|| = √(0.6² + 0.7²) = √0.85 = 0.922<br/>||v₂|| = √(0.8² + 0.75²) = √1.2025 = 1.097]\n        cos[Coherence:<br/>cos(v₁,v₂) = 1.005/(0.922×1.097)<br/>= 1.005/1.011 = 0.994]\n    end\n    \n    A --> to\n    A --> from\n    calc_to --> v1_construct\n    calc_from --> v2_construct\n    reg --> reg_calc\n    reg_calc --> v1_construct\n    reg_calc --> v2_construct\n    v1_construct --> dot\n    v2_construct --> dot\n    v1_construct --> norm\n    v2_construct --> norm\n    dot --> cos\n    norm --> cos\n    \n    result[High coherence 0.994:<br/>Tech A's network position<br/>aligns with region's<br/>specialization pattern]\n    cos --> result\n    \n    classDef techNode fill:#ffe6e6,stroke:#333,stroke-width:2px\n    classDef calcNode fill:#e6f3ff,stroke:#333,stroke-width:2px\n    classDef resultNode fill:#e6ffe6,stroke:#333,stroke-width:2px\n    \n    class A,B,C,D techNode\n    class to,from,calc_to,calc_from,reg_calc,v1_construct,v2_construct,dot,norm,cos calcNode\n    class result resultNode\n```\n\n\n### Interpretation\n\nCoherence ranges from -1 to 1:\n\n- **High coherence** ($\\approx 1$): Technology $i$'s FITS network position (both incoming and outgoing connections to category $c$) closely matches the average network position of technologies in which region $r$ specializes within category $c$. The region's existing capabilities align with the structural prerequisites and consequences of technology $i$.\n- **Neutral coherence** ($\\approx 0$): Misalignment between technology $i$'s relational structure and regional specialization patterns.\n- **Negative coherence** ($\\approx -1$): Technology $i$'s network position is opposite to the region's specialization structure (e.g., $i$ receives inputs from categories where the region sends outputs).\n\n### Empirical Application\n\nCoherence serves two roles in our empirical analysis:\n\n1. **Interaction with Potential**: Test whether high potential translates to actual diversification only when coherence is also high (H2a: technology-specific characteristics moderated by regional knowledge coherence)\n\n2. **Regional Infrastructure Measure**: Aggregate coherence across a region's non-specialized technologies indicates how well the regional portfolio is \"positioned\" in the FITS network for future diversification (captures knowledge infrastructure quality)\n\nBy incorporating coherence, we test whether successful diversification requires not just predicted feasibility (potential) and related capabilities (traditional relatedness), but also structural alignment between regional portfolios and network prerequisites—a form of contextualization that traditional measures cannot capture.\n\n\n# Summary of Methodological Framework\n\nOur approach replaces traditional relatedness constructs with machine learning-derived measures that enable contextualized diversification analysis:\n\n- **Technological Potential** ($p_{r,t,y}$): Region-specific, non-linear, time-varying probabilities replace linear relatedness density\n- **FITS Network** ($W_{t \\to t'}$): Asymmetric, predictive dependencies replace symmetric co-occurrence-based relatedness  \n- **Coherence** ($\\text{Coherence}_{r,t,c,y}$): Structural alignment between regional portfolios and technology network positions captures knowledge infrastructure quality\n\nTogether, these measures allow testing how diversification is contingent on regional knowledge infrastructure (RQ2), national ecosystem characteristics (RQ3), and spatial factors (RQ4) in ways that traditional relatedness frameworks cannot—addressing the core problem of contextualizing diversification strategies beyond path dependency identification.","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"potential.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","bibliography":["references.bib"],"browser":"brave","theme":"cosmo","lot":true,"lof":true,"fontsize":"12pt","linestretch":1.5,"mermaid":{"theme":"default"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}